'''
    Evaluate results generated by models
'''

import os
import json
import argparse
from eval import Evaluator
import pdb

def read_candidates(testfile, dataset):
    candidates = {}
    with open(os.path.join(testfile), 'r', encoding='utf-8') as fin:
        for idx, line in enumerate(fin):
            jterm = json.loads(line.strip())
            if dataset in ['ImageEdit', 'clevr']:
                img_id = jterm['ImgId']
            elif dataset in ['bird']:
                img1_id = jterm['ImgId'].split('_')[0] + '.jpg'
                img2_id = jterm['ImgId'].split('_')[1] + '.jpg'
                img_id = img1_id+'_'+img2_id
            else:
                print("dataset {} not exits! ".format(dataset))
            if testfile.endswith('.json'):
                candidates[img_id] = jterm['candidates']
            else:
                candidates[img_id] = [' '.join(c for c in jterm['candidates'])]                
    return candidates




if __name__ == '__main__':
    # example command: python3 eval_models.py --dataset bird --testfile 
    parser = argparse.ArgumentParser(description='Generate ground truth for evalation')
    parser.add_argument('--testfile', help='candidate data file', default='') # experiments/finetune_clver_neg_tfidf6_t1.0/results.json
    parser.add_argument('--gtfile', help='groundturth data file', default='') # dataset_clver/test.json
    parser.add_argument('--dataset', help='dataset', default='clevr')
    parser.add_argument('--type', help='early stop type', type=str, default='')
    args = parser.parse_args()
    print("--------------This is evaluate {}--------------".format(args.dataset))

    # read candidate file
    testfile = None
    gtfile = None
    testfile = args.testfile
    candidates = read_candidates(testfile, args.dataset)
    all_references = {}
    cand = {}
    
    # read groundtruth file 
    if args.gtfile != '':
        gtfile = args.gtfile
    else:
        gtfile = '/data2/wwy/caption/data/{}/test.json'.format(args.dataset)
    with open(gtfile, 'r', encoding = 'utf-8') as file:
        for idx, line in enumerate(file):
            jterm = json.loads(line)
            if args.dataset in ['ImageEdit', 'bird', 'clevr']:
                img1_id = jterm['img1']
                img2_id = jterm['img2']
            else:
                print("dataset {} not exists!".format(args.dataset))
            img_id = img1_id+'_'+img2_id
            all_references[img_id] = jterm['sentences']

    # keep the key of ref and candidate same
    references = {}
    for key, value in candidates.items():
        references[key] = all_references[key]
        
    print('Candidates ', len(candidates))
    print('References ', len(references))
    evaluator = Evaluator(references, candidates)
    evaluator.evaluate()        
